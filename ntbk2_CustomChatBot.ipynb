{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom Chatbot Notebook",
   "id": "a71c5706072dcb2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "An OpenAI client is initialised by using environment variables and a tokenizer is set up for a specific model (`gpt-4o-mini-2024-07-18`). Also,the necessary libraries and custom utility functions are imported.",
   "id": "876d4a4fd073a812"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:41.390959Z",
     "start_time": "2025-03-12T18:45:39.150915Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "# Custom Functions\n",
    "from fncs.utilities import (\n",
    "    create_openai_client,\n",
    "    response_generator,\n",
    "    prompt_builder,\n",
    "    calculate_total_cost\n",
    "    )\n",
    "from fncs.retrieval import (\n",
    "    get_embedding,\n",
    "    search_text,\n",
    "    control_chunk_context\n",
    "    )\n",
    "\n",
    "from fncs.prompt_templates import (\n",
    "    user_prompt,\n",
    "    user_prompt_without_context\n",
    ")\n",
    "\n",
    "# Load environment vars:\n",
    "load_dotenv()\n",
    "base_url_voc = os.getenv(\"OPENAI_BASE_VOC\")\n",
    "api_key_voc = os.getenv(\"OPENAI_API_VOC\")\n",
    "# Deployment model names\n",
    "chat_name = 'gpt-4o' # 'gpt-4o-mini-2024-07-18' # 'gpt-4o-mini'\n",
    "emb_name = 'text-embedding-3-large'\n",
    "# Initialising OpenAI client\n",
    "openai_client = create_openai_client(api_key= api_key_voc, base_url= base_url_voc)\n",
    "tokenizer = tiktoken.encoding_for_model(chat_name)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading dataset",
   "id": "aa1832c099f587ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:41.486935Z",
     "start_time": "2025-03-12T18:45:41.400704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "proj_dir = Path(os.getcwd())\n",
    "df = pd.read_csv(proj_dir / \"data\" / \"2023_fashion_trends_embeddings.csv\")\n",
    "df.head(3)"
   ],
   "id": "9233858f77e0c6bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  \\nFashion trends according to refinery29\\n\\nSo...   \n",
       "1  \\nFashion trends according to refinery29\\n\\nSo...   \n",
       "2  \\nFashion trends according to refinery29\\n\\nSo...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.06195216625928879, -0.007596897892653942, ...  \n",
       "1  [-0.0732918530702591, -0.014976361766457558, -...  \n",
       "2  [-0.05401710420846939, -0.003982114605605602, ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nFashion trends according to refinery29\\n\\nSo...</td>\n",
       "      <td>[-0.06195216625928879, -0.007596897892653942, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nFashion trends according to refinery29\\n\\nSo...</td>\n",
       "      <td>[-0.0732918530702591, -0.014976361766457558, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nFashion trends according to refinery29\\n\\nSo...</td>\n",
       "      <td>[-0.05401710420846939, -0.003982114605605602, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The embeddings are stored as text/string in the DataFrame and need to be converted to lists/arrays",
   "id": "dfb834f8176e49a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:43.182403Z",
     "start_time": "2025-03-12T18:45:41.859626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "# Converting the string representations of embeddings to actual lists\n",
    "df['embeddings'] = df['embeddings'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
   ],
   "id": "72f7af3db628d262",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Checking transformation",
   "id": "ea2d89ae8d023bd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:43.240174Z",
     "start_time": "2025-03-12T18:45:43.234768Z"
    }
   },
   "cell_type": "code",
   "source": "type(df[['embeddings']].iloc[0].values[0])",
   "id": "7d4c69ab4591f282",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculating Cosine Distances based on query\n",
   "id": "16b223bc1c9826e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below I create a query string about fashion trends in 2023. Then, by using the `get_embedding` function, the embeddings of the query are generated, by passing the query, OpenAI client, and embedding model as inputs.",
   "id": "93ba9094776a441b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.178284Z",
     "start_time": "2025-03-12T18:45:43.246388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is the most popular fashion trend about pants in 2023?\"\n",
    "query_emb = get_embedding(text=query, client = openai_client, model=emb_name)"
   ],
   "id": "54410f634493630e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The DataFrame `df` is sorted based on the cosine distance between the query embedding (`query_emb`) and the embeddings in the DataFrame using the `search_text` function, and stores the result in `df_sorted`.",
   "id": "586755641dd11503"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.257586Z",
     "start_time": "2025-03-12T18:45:45.183855Z"
    }
   },
   "cell_type": "code",
   "source": "df_sorted = search_text(df=df, embs_query=query_emb, cosine='distance')",
   "id": "651fdb4f27f1ee03",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.288999Z",
     "start_time": "2025-03-12T18:45:45.275821Z"
    }
   },
   "cell_type": "code",
   "source": "df_sorted.head()",
   "id": "9c4e84a9dd56756e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 text  \\\n",
       "1   \\nFashion trends according to refinery29\\n\\nSo...   \n",
       "58  \\nFashion trends according to whowhatwear\\n\\nS...   \n",
       "3   \\nFashion trends according to refinery29\\n\\nSo...   \n",
       "44  \\nFashion trends according to whowhatwear\\n\\nS...   \n",
       "45  \\nFashion trends according to whowhatwear\\n\\nS...   \n",
       "\n",
       "                                           embeddings  distance  \n",
       "1   [-0.0732918530702591, -0.014976361766457558, -...  0.288696  \n",
       "58  [-0.05073591694235802, -0.018371405079960823, ...  0.319315  \n",
       "3   [-0.052798643708229065, -0.02721790410578251, ...  0.326079  \n",
       "44  [-0.05533209815621376, -0.032554663717746735, ...  0.329414  \n",
       "45  [-0.024114221334457397, -0.018797021359205246,...  0.349743  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nFashion trends according to refinery29\\n\\nSo...</td>\n",
       "      <td>[-0.0732918530702591, -0.014976361766457558, -...</td>\n",
       "      <td>0.288696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>\\nFashion trends according to whowhatwear\\n\\nS...</td>\n",
       "      <td>[-0.05073591694235802, -0.018371405079960823, ...</td>\n",
       "      <td>0.319315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nFashion trends according to refinery29\\n\\nSo...</td>\n",
       "      <td>[-0.052798643708229065, -0.02721790410578251, ...</td>\n",
       "      <td>0.326079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\\nFashion trends according to whowhatwear\\n\\nS...</td>\n",
       "      <td>[-0.05533209815621376, -0.032554663717746735, ...</td>\n",
       "      <td>0.329414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\\nFashion trends according to whowhatwear\\n\\nS...</td>\n",
       "      <td>[-0.024114221334457397, -0.018797021359205246,...</td>\n",
       "      <td>0.349743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt Template\n",
    "\n"
   ],
   "id": "97638c85ae6d747d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating the system prompt to be used in the chatbot",
   "id": "da394a06d778b32a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.401617Z",
     "start_time": "2025-03-12T18:45:45.397202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are an expert fashion trend analyser. Based only on the provided information you must analyse and summarise the trends and provide an accurate answer.\"\n",
    "\n",
    "print(f\"System Prompt Tokens: {len(tokenizer.encode(system_prompt))}\")"
   ],
   "id": "16608bc3cc579ba2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt Tokens: 28\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calling the user prompt templates functions that will",
   "id": "fc2cdc335fb53bc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.490425Z",
     "start_time": "2025-03-12T18:45:45.485617Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"User Prompt (with context) Tokens BEFORE context insertion: {len(tokenizer.encode(user_prompt()))}\")",
   "id": "732e48236e9a6d72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt (with context) Tokens BEFORE context insertion: 130\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.511837Z",
     "start_time": "2025-03-12T18:45:45.508039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# to be used in performance demonstration later\n",
    "print(f\"User Prompt (without context) Tokens BEFORE context insertion: {len(tokenizer.encode(user_prompt_without_context()))}\")"
   ],
   "id": "f730b283e8594761",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt (without context) Tokens BEFORE context insertion: 94\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Apply token controller function ( fnc: control_chunk_context )",
   "id": "3649988fc071c9bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The variable `max_token_count` to 1000, serves as a limit for the total number of tokens allowed in a prompt.",
   "id": "839f6afd7c2c2e41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.544985Z",
     "start_time": "2025-03-12T18:45:45.541350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#parameter that control the prompt tokens:\n",
    "max_token_count = 1000"
   ],
   "id": "22322f84eb10bf97",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The code below calculates the current token count of the prompts (system and user) and generates a context by selecting data from the sorted DataFrame (`df_sorted`) based on a maximum allowed token limit (`max_token_count`) using the `control_chunk_context` function.",
   "id": "3c777d5527194df7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.591077Z",
     "start_time": "2025-03-12T18:45:45.585916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_token_count = len(tokenizer.encode(user_prompt())) + len(tokenizer.encode(system_prompt))\n",
    "# Create context from sorted dataframe according to the max token limit\n",
    "context = control_chunk_context(\n",
    "    df_sorted,\n",
    "    current_token_count,\n",
    "    max_token_count,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ],
   "id": "ff7b5de9fb7ce93e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Below, the final `user_prompt` is created by inserting the generated `context` into the prompt template and by formatting it with the query and context.",
   "id": "792d744256c0ffba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.648887Z",
     "start_time": "2025-03-12T18:45:45.644539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prompt template params\n",
    "context_inprompt = \"\\n----\\n\".join(context)\n",
    "user_prompt_0 = user_prompt().format(query, context_inprompt)\n",
    "\n",
    "print(user_prompt_0)"
   ],
   "id": "8987fcd4455e42bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ***Question: What is the most popular fashion trend about pants in 2023?\n",
      "    \n",
      "    ***Context:\n",
      "    <--Start of Context-->\n",
      "    \n",
      "Fashion trends according to refinery29\n",
      "\n",
      "Source Title: 7 Fashion Trends That Will Take Over 2023 — Shop Them Now\n",
      "\n",
      "2023 Fashion Trend: Cargo Pants. Utilitarian wear is in for 2023, which sets the stage for the return of the cargo pant. But these aren't the shapeless, low-rise pants of the Y2K era. For spring, this trend is translated into tailored silhouettes, interesting pocket placements, elevated fabrics like silk and organza, and colors that go beyond khaki and olive.\n",
      "\n",
      "Source URL: https://www.refinery29.com/en-us/fashion-trends-2023\n",
      "\n",
      "----\n",
      "\n",
      "Fashion trends according to whowhatwear\n",
      "\n",
      "Source Title: Spring/Summer 2023 Fashion Trends: 21 Expert-Approved Looks You Need to See\n",
      "\n",
      "Every buyer I have spoken to has been most excited by the many pairs of perfectly cut trousers in the spring/summer 2023 collections, which actually should hardly come as a surprise. It's been the year of the trouser after all, and that looks set to continue as designers have become more and more playful with their pants. From pedal pushers to wide-leg, cargos to puddle hemlines, the gang's all here, and just in the nick of time. \n",
      "\n",
      "Source URL: https://www.whowhatwear.com/spring-summer-2023-fashion-trends/\n",
      "\n",
      "----\n",
      "\n",
      "Fashion trends according to refinery29\n",
      "\n",
      "Source Title: 7 Fashion Trends That Will Take Over 2023 — Shop Them Now\n",
      "\n",
      "2023 Fashion Trend: Denim Reimagined. From double-waisted jeans to carpenter jeans, it's been a while since we were this excited about denim trends. It seems like even the most luxe runway designers agree, sending out strapless dresses, shirting, and even undergarments and shoes (thigh-high-boot-jean hybrids anyone?) in the material. Whatever category you decide on, opt for timeless cuts and silhouettes that can stay in your closet rotation once the novelty wears off.\n",
      "\n",
      "Source URL: https://www.refinery29.com/en-us/fashion-trends-2023\n",
      "\n",
      "----\n",
      "\n",
      "Fashion trends according to whowhatwear\n",
      "\n",
      "Source Title: Spring/Summer 2023 Fashion Trends: 21 Expert-Approved Looks You Need to See\n",
      "\n",
      "I get it. Some of the trends on this list might not translate seamlessly into everyday life (if you're prepared to wear a completely sheer skirt to run errands in, more power to you). However, if you're looking to invest in something you'll genuinely get the wear of, look no further. Between wide-legs and puddle hemlines, slouchy-fit trousers were one of the biggest trends of 2022. Now, for spring 2023, the best jeans will feature these same design traits. From high-waisted dark-wash flares at Tibi to Bally's effortless double-denim moment complete with floor-grazing lengths, looser-fit denim is resolutely where it's at.\n",
      "\n",
      "Source URL: https://www.whowhatwear.com/spring-summer-2023-fashion-trends/\n",
      "\n",
      "    <--End of Context-->\n",
      "    \n",
      "    **Instructions:\n",
      "    - Answer based ONLY on the provided context above\n",
      "    - Do not include external knowledge\n",
      "    - Be concise and specific\n",
      "    \n",
      "    **Required Format:\n",
      "    1. Answer:\n",
      "       [Your detailed response here]\n",
      "    \n",
      "    2. Sources:\n",
      "       • [Unique Source URL 1]\n",
      "       • [Unique Source URL 2]\n",
      "       • [...]\n",
      "    \n",
      "    Note: If the answer cannot be determined from the provided context,\n",
      "    state: \"Cannot be determined from the given context.\"\n",
      "    \n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:45.683293Z",
     "start_time": "2025-03-12T18:45:45.678843Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"User Prompt Tokens AFTER context insertion: {len(tokenizer.encode(user_prompt_0))}\")",
   "id": "684eb7487a4e49ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Tokens AFTER context insertion: 763\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "**Finally, the code below generates a final prompt using the `prompt_builder` function by combining the system and user prompts. It then sends the prompt to the OpenAI model (`chat_model`) using the `response_generator` function with specified additional options (e.g., `temperature=0.1`) to generate an AI response. It also calculates the total cost in EUR based on the API usage (`response_full.usage`) for the specific deployment (`gpt-4o`).**"
   ],
   "id": "31565197da769294"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:49.069812Z",
     "start_time": "2025-03-12T18:45:45.715213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_0)\n",
    "additional_options = {\"temperature\": 0.1,}\n",
    "response, response_full = response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options=additional_options)\n",
    "cost_eur = calculate_total_cost(response_usage= response_full.usage,\n",
    "                                deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur} eur')"
   ],
   "id": "61a47f0eda0f0944",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00330951342 eur\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:49.092272Z",
     "start_time": "2025-03-12T18:45:49.088120Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "id": "834e12f3fc4d6430",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   The most popular fashion trend about pants in 2023 is the return of cargo pants with a modern twist, featuring tailored silhouettes, interesting pocket placements, and elevated fabrics. Additionally, perfectly cut trousers, including wide-leg and slouchy-fit styles, are also trending, with designers becoming more playful with their designs.\n",
      "\n",
      "2. Sources:\n",
      "   • https://www.refinery29.com/en-us/fashion-trends-2023\n",
      "   • https://www.whowhatwear.com/spring-summer-2023-fashion-trends/\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:49.115460Z",
     "start_time": "2025-03-12T18:45:49.111120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Total Tokens: ', response_full.usage.total_tokens)\n",
    "print('Total Completion Tokens: ', response_full.usage.completion_tokens)\n",
    "print('Total Prompt Tokens: ', response_full.usage.prompt_tokens)"
   ],
   "id": "83efedf17ce7c862",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:  915\n",
      "Total Completion Tokens:  113\n",
      "Total Prompt Tokens:  802\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Demonstrating Performance\n",
    "\n",
    "Below I demonstrate through some examples how using a custom prompt significantly enhances the performance and accuracy of responses from the OpenAI model compared to basic (generic) prompts. I showcase two different example queries about 2023 fashion trends, providing the responses produced using the custom context-based prompt and a basic prompt (without context).\n",
    "\n",
    "In other words, the comparison made below, clearly illustrates that custom prompts, enriched with relevant contextual information, greatly enhance the accuracy, specificity, and usefulness of model-generated responses. Basic prompts, without contextual enrichment, yield generic and less informative answers."
   ],
   "id": "7514793b17a761c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1\n",
    "**Question**: According to Vogue, what is a new trend presented by Prada on New York Fashion Week?"
   ],
   "id": "6de426f99dc8bcfe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:49.155424Z",
     "start_time": "2025-03-12T18:45:49.152474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_1 = \"According to Vogue, what is a new trend presented by Prada on New York Fashion Week?\"\n",
    "max_token_count = 1000"
   ],
   "id": "ca6add389d1d2bed",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1.1 Using custom prompt with context:",
   "id": "115fe596353ed328"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:53.374744Z",
     "start_time": "2025-03-12T18:45:49.189370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_emb = get_embedding(text=query_1, client = openai_client, model=emb_name)\n",
    "df_sorted = search_text(df=df, embs_query=query_emb, cosine='distance')\n",
    "\n",
    "current_token_count = len(tokenizer.encode(user_prompt())) + len(tokenizer.encode(system_prompt))\n",
    "# Create context from sorted dataframe according to the max token limit\n",
    "context = control_chunk_context(chunks_sorted_df=df_sorted,\n",
    "                                current_token_count=current_token_count,\n",
    "                                max_token_count=max_token_count,\n",
    "                                tokenizer = tokenizer)\n",
    "context_inprompt = \"\\n----\\n\".join(context)\n",
    "user_prompt_1 = user_prompt().format(query_1, context_inprompt)\n",
    "\n",
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_1)\n",
    "additional_options = {\"temperature\": 0.1,}\n",
    "\n",
    "response_1_1, response_full_1_1 = \\\n",
    "    response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options= additional_options)\n",
    "\n",
    "cost_eur_1_1 = \\\n",
    "    calculate_total_cost(response_usage= response_full.usage, deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_1_1} eur')\n"
   ],
   "id": "e16c21bcf8e08b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00330951342 eur\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:53.388549Z",
     "start_time": "2025-03-12T18:45:53.385156Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_1_1)",
   "id": "788ec7d99d399e93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   Prada presented a trend of \"Perfectly Imperfect\" during New York Fashion Week, featuring a satin midi skirt that evokes a sense of \"unfinishedness\" with an irregularly dyed print and a slit designed to look like the skirt is torn.\n",
      "\n",
      "2. Sources:\n",
      "   • https://www.vogue.com/article/spring-2023-trends-editors-picks\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1.2 Using basic prompt with no context:",
   "id": "53148938b0d50835"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:55.617212Z",
     "start_time": "2025-03-12T18:45:53.418066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_without_context().format(query_1) )\n",
    "additional_options = {\"temperature\": 0.1,}\n",
    "\n",
    "response_1_2, response_full_1_2 = response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options=additional_options)\n",
    "cost_eur_1_2 = calculate_total_cost(response_usage= response_full.usage,\n",
    "                                deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_1_2} eur')"
   ],
   "id": "ceaaf7e040805a15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00330951342 eur\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:55.639756Z",
     "start_time": "2025-03-12T18:45:55.636516Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_1_2)",
   "id": "bb251c59934d3f64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   Cannot be determined as I do not have enough the knowledge to answer this question.\n",
      "\n",
      "2. Sources:\n",
      "   • [Not available]\n",
      "   • [Not available]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2\n",
    "**Question**: According to glamour magazine and whowhatwear.com what are the denim fashion trends for the year 2023?"
   ],
   "id": "2e50a8bd0da9e2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:45:55.662638Z",
     "start_time": "2025-03-12T18:45:55.659538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_2 = \"According to glamour magazine and whowhatwear.com what are the denim fashion trends for the year 2023?\"\n",
    "max_token_count = 1000"
   ],
   "id": "aa58c3192fbcaed3",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2.1 Using custom prompt with context:",
   "id": "d36952f0eb9fd262"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:46:02.174164Z",
     "start_time": "2025-03-12T18:45:55.682720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_emb = get_embedding(text=query_2, client = openai_client, model=emb_name)\n",
    "df_sorted = search_text(df=df, embs_query=query_emb, cosine='distance')\n",
    "\n",
    "current_token_count = len(tokenizer.encode(user_prompt())) + len(tokenizer.encode(system_prompt))\n",
    "# Create context from sorted dataframe according to the max token limit\n",
    "context = control_chunk_context(chunks_sorted_df=df_sorted,\n",
    "                                current_token_count=current_token_count,\n",
    "                                max_token_count=max_token_count,\n",
    "                                tokenizer = tokenizer)\n",
    "context_inprompt = \"\\n----\\n\".join(context)\n",
    "user_prompt_2 = user_prompt().format(query_2, context_inprompt)\n",
    "\n",
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_2)\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_2_1, response_full_2_1 = \\\n",
    "    response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options= additional_options)\n",
    "\n",
    "cost_eur_2_1 = \\\n",
    "    calculate_total_cost(response_usage= response_full.usage, deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_2_1} eur')"
   ],
   "id": "4e49d54c04f16346",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00330951342 eur\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:46:02.196477Z",
     "start_time": "2025-03-12T18:46:02.192899Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_2_1)",
   "id": "ed6c6784e187478",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   According to Glamour magazine, the denim fashion trend for 2023 is baggy denim. Denim remains as baggy as it has been, if not even looser, with a great light-wash pair of jeans offering endless styling potential. \n",
      "\n",
      "   According to WhoWhatWear, the trend is towards more relaxed silhouettes in denim, with styles so relaxed they might as well be joggers. The trend is moving away from skinny jeans to wide-leg trousers.\n",
      "\n",
      "2. Sources:\n",
      "   • https://www.glamour.com/story/spring-fashion-trends\n",
      "   • https://www.whowhatwear.com/spring-summer-2023-fashion-trends/\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2.2 Using basic prompt with no context:",
   "id": "cb42ba21ce7040b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:46:05.353535Z",
     "start_time": "2025-03-12T18:46:02.230575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_without_context().format(query_2) )\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_2_2, response_full_2_2 = response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options=additional_options)\n",
    "\n",
    "cost_eur_2_2 = calculate_total_cost(response_usage= response_full.usage,deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_2_2} eur')"
   ],
   "id": "9139d4de112837db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00330951342 eur\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:46:05.423905Z",
     "start_time": "2025-03-12T18:46:05.420360Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_2_2)",
   "id": "6102b25283d411a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   The denim fashion trends for 2023, as reported by Glamour Magazine and Who What Wear, include a focus on baggy and relaxed fits, low-rise jeans making a comeback, and the popularity of cargo-style denim. Additionally, there is an emphasis on vintage-inspired washes and patchwork designs, as well as the continued presence of straight-leg and wide-leg silhouettes.\n",
      "\n",
      "2. Sources:\n",
      "   • Cannot provide specific URLs as I do not have access to external content.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:58:09.942109Z",
     "start_time": "2025-03-12T18:58:09.938466Z"
    }
   },
   "cell_type": "code",
   "source": "print('Notebook Finished')",
   "id": "f710af2445d92eec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Finished\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
