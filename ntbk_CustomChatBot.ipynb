{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom Chatbot Notebook",
   "id": "a71c5706072dcb2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "An OpenAI client is initialised by using environment variables and a tokenizer is set up for a specific model (`gpt-4o-mini-2024-07-18`). Also,the necessary libraries and custom utility functions are imported.",
   "id": "876d4a4fd073a812"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:09.059344Z",
     "start_time": "2025-03-10T18:42:09.044497Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "# Custom Functions\n",
    "from fncs.utilities import (\n",
    "    create_openai_client,\n",
    "    response_generator,\n",
    "    prompt_builder,\n",
    "    calculate_total_cost\n",
    "    )\n",
    "from fncs.retrieval import (\n",
    "    get_embedding,\n",
    "    search_text,\n",
    "    control_chunk_context\n",
    "    )\n",
    "\n",
    "# Load environment vars:\n",
    "load_dotenv()\n",
    "base_url_voc = os.getenv(\"OPENAI_BASE_VOC\")\n",
    "api_key_voc = os.getenv(\"OPENAI_API_VOC\")\n",
    "# Deployment model names\n",
    "chat_name = 'gpt-4o' # 'gpt-4o-mini-2024-07-18' # 'gpt-4o-mini'\n",
    "emb_name = 'text-embedding-3-large'\n",
    "# Initialising OpenAI client\n",
    "openai_client = create_openai_client(api_key= api_key_voc, base_url= base_url_voc)\n",
    "tokenizer = tiktoken.encoding_for_model(chat_name)"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading dataset",
   "id": "aa1832c099f587ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:09.141407Z",
     "start_time": "2025-03-10T18:42:09.077255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "proj_dir = Path(os.getcwd())\n",
    "df = pd.read_csv(proj_dir / \"data\" / \"2023_fashion_trends_embeddings.csv\")\n",
    "df.head(3)"
   ],
   "id": "9233858f77e0c6bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "1  Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "2  Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.06084602698683739, -0.00787690281867981, -...  \n",
       "1  [-0.06700262427330017, -0.014003804884850979, ...  \n",
       "2  [-0.05102064833045006, -0.00858586560934782, -...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.06084602698683739, -0.00787690281867981, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.06700262427330017, -0.014003804884850979, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.05102064833045006, -0.00858586560934782, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The embeddings are stored as text/string in the DataFrame and need to be converted to lists/arrays",
   "id": "dfb834f8176e49a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:10.239126Z",
     "start_time": "2025-03-10T18:42:09.185636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "# Converting the string representations of embeddings to actual lists\n",
    "df['embeddings'] = df['embeddings'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
   ],
   "id": "72f7af3db628d262",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Checking transformation",
   "id": "ea2d89ae8d023bd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:10.344521Z",
     "start_time": "2025-03-10T18:42:10.340151Z"
    }
   },
   "cell_type": "code",
   "source": "type(df[['embeddings']].iloc[0].values[0])",
   "id": "7d4c69ab4591f282",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculating Cosine Distances based on query\n",
   "id": "16b223bc1c9826e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below I create a query string about fashion trends in 2023. Then, by using the `get_embedding` function, the embeddings of the query are generated, by passing the query, OpenAI client, and embedding model as inputs.",
   "id": "93ba9094776a441b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:12.711653Z",
     "start_time": "2025-03-10T18:42:10.354670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is the most popular fashion trend about pants in 2023?\"\n",
    "query_emb = get_embedding(text=query, client = openai_client, model=emb_name)"
   ],
   "id": "54410f634493630e",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The DataFrame `df` is sorted based on the cosine distance between the query embedding (`query_emb`) and the embeddings in the DataFrame using the `search_text` function, and stores the result in `df_sorted`.",
   "id": "586755641dd11503"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:12.777266Z",
     "start_time": "2025-03-10T18:42:12.720732Z"
    }
   },
   "cell_type": "code",
   "source": "df_sorted = search_text(df=df, embs_query=query_emb, cosine='distance')",
   "id": "651fdb4f27f1ee03",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:12.815483Z",
     "start_time": "2025-03-10T18:42:12.804608Z"
    }
   },
   "cell_type": "code",
   "source": "df_sorted.head()",
   "id": "9c4e84a9dd56756e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 text  \\\n",
       "1   Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "3   Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "58  Title: Spring/Summer 2023 Fashion Trends: 21 E...   \n",
       "44  Title: Spring/Summer 2023 Fashion Trends: 21 E...   \n",
       "19  Title: 9 Spring 2023 Fashion Trends Youâ€™ll Wan...   \n",
       "\n",
       "                                           embeddings  distance  \n",
       "1   [-0.06700262427330017, -0.014003804884850979, ...  0.273721  \n",
       "3   [-0.05067730322480202, -0.02512504905462265, -...  0.307084  \n",
       "58  [-0.03485928103327751, -0.015784457325935364, ...  0.309776  \n",
       "44  [-0.04672637954354286, -0.03269721940159798, -...  0.310095  \n",
       "19  [-0.04425228014588356, -0.035396404564380646, ...  0.355568  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.06700262427330017, -0.014003804884850979, ...</td>\n",
       "      <td>0.273721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.05067730322480202, -0.02512504905462265, -...</td>\n",
       "      <td>0.307084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Title: Spring/Summer 2023 Fashion Trends: 21 E...</td>\n",
       "      <td>[-0.03485928103327751, -0.015784457325935364, ...</td>\n",
       "      <td>0.309776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Title: Spring/Summer 2023 Fashion Trends: 21 E...</td>\n",
       "      <td>[-0.04672637954354286, -0.03269721940159798, -...</td>\n",
       "      <td>0.310095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Title: 9 Spring 2023 Fashion Trends Youâ€™ll Wan...</td>\n",
       "      <td>[-0.04425228014588356, -0.035396404564380646, ...</td>\n",
       "      <td>0.355568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt Template\n",
    "\n"
   ],
   "id": "97638c85ae6d747d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating the system prompt to be used in the chatbot",
   "id": "da394a06d778b32a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:12.856455Z",
     "start_time": "2025-03-10T18:42:12.853635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are an expert fashion trend analyser. Based only on the provided information you must analyse and summarise the trends and provide an accurate answer.\"\n",
    "\n",
    "print(f\"System Prompt Tokens: {len(tokenizer.encode(system_prompt))}\")"
   ],
   "id": "16608bc3cc579ba2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt Tokens: 28\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating the user prompt to be used in the chatbot",
   "id": "fc2cdc335fb53bc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:12.910347Z",
     "start_time": "2025-03-10T18:42:12.906703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_prompt = \\\n",
    "\"\"\"\n",
    "***Question: {}\n",
    "\n",
    "***Context:\n",
    "<--Start of Context-->\n",
    "{}\n",
    "<--End of Context-->\n",
    "\n",
    "**Instructions:\n",
    "- Answer based ONLY on the provided context above\n",
    "- Do not include external knowledge\n",
    "- Be concise and specific\n",
    "\n",
    "**Required Format:\n",
    "1. Answer:\n",
    "   [Your detailed response here]\n",
    "\n",
    "2. Key Points:\n",
    "   â€¢ [Bullet point 1]\n",
    "   â€¢ [Bullet point 2]\n",
    "   â€¢ [...]\n",
    "\n",
    "3. Sources:\n",
    "   â€¢ [Source URL 1]\n",
    "   â€¢ [Source URL 2]\n",
    "\n",
    "Note: If the answer cannot be determined from the provided context,\n",
    "state: \"Cannot be determined from the given context.\"\n",
    "\"\"\"\n",
    "print(f\"User Prompt Tokens BEFORE context insertion: {len(tokenizer.encode(user_prompt))}\")"
   ],
   "id": "732e48236e9a6d72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Tokens BEFORE context insertion: 130\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:13.012510Z",
     "start_time": "2025-03-10T18:42:13.008728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# to be used in performance demonstration later\n",
    "user_prompt_without_context = \\\n",
    "\"\"\"\n",
    "***Question: {}\n",
    "\n",
    "**Instructions:\n",
    "- Be concise and specific\n",
    "\n",
    "**Required Format:\n",
    "1. Answer:\n",
    "   [Your detailed response here]\n",
    "\n",
    "2. Key Points:\n",
    "   â€¢ [Bullet point 1]\n",
    "   â€¢ [Bullet point 2]\n",
    "   â€¢ [...]\n",
    "\n",
    "3. Sources:\n",
    "   â€¢ [Source URL 1]\n",
    "   â€¢ [Source URL 2]\n",
    "\"\"\"\n",
    "print(f\"User Prompt Tokens BEFORE context insertion: {len(tokenizer.encode(user_prompt))}\")"
   ],
   "id": "f730b283e8594761",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Tokens BEFORE context insertion: 130\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Apply token controller function ( fnc: control_chunk_context )",
   "id": "3649988fc071c9bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The variable `max_token_count` to 1000, serves as a limit for the total number of tokens allowed in a prompt.",
   "id": "839f6afd7c2c2e41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:13.059828Z",
     "start_time": "2025-03-10T18:42:13.057199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#parameter that control the prompt tokens:\n",
    "max_token_count = 1000"
   ],
   "id": "22322f84eb10bf97",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The code below calculates the current token count of the prompts (system and user) and generates a context by selecting data from the sorted DataFrame (`df_sorted`) based on a maximum allowed token limit (`max_token_count`) using the `control_chunk_context` function.",
   "id": "3c777d5527194df7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:13.082859Z",
     "start_time": "2025-03-10T18:42:13.077004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_token_count = len(tokenizer.encode(user_prompt)) + len(tokenizer.encode(system_prompt))\n",
    "# Create context from sorted dataframe according to the max token limit\n",
    "context = control_chunk_context(\n",
    "    df_sorted,\n",
    "    current_token_count,\n",
    "    max_token_count,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ],
   "id": "ff7b5de9fb7ce93e",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Below, the final `user_prompt` is created by inserting the generated `context` into the prompt template and by formatting it with the query and context.",
   "id": "792d744256c0ffba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:13.101796Z",
     "start_time": "2025-03-10T18:42:13.098256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prompt template params\n",
    "context_inprompt = \"\\n----\\n\".join(context)\n",
    "user_prompt_0 = user_prompt.format(query, context_inprompt)\n",
    "\n",
    "print(user_prompt)"
   ],
   "id": "8987fcd4455e42bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Question: {}\n",
      "\n",
      "***Context:\n",
      "<--Start of Context-->\n",
      "{}\n",
      "<--End of Context-->\n",
      "\n",
      "**Instructions:\n",
      "- Answer based ONLY on the provided context above\n",
      "- Do not include external knowledge\n",
      "- Be concise and specific\n",
      "\n",
      "**Required Format:\n",
      "1. Answer:\n",
      "   [Your detailed response here]\n",
      "\n",
      "2. Key Points:\n",
      "   â€¢ [Bullet point 1]\n",
      "   â€¢ [Bullet point 2]\n",
      "   â€¢ [...]\n",
      "\n",
      "3. Sources:\n",
      "   â€¢ [Source URL 1]\n",
      "   â€¢ [Source URL 2]\n",
      "\n",
      "Note: If the answer cannot be determined from the provided context,\n",
      "state: \"Cannot be determined from the given context.\"\n",
      "\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:13.181453Z",
     "start_time": "2025-03-10T18:42:13.177658Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"User Prompt Tokens AFTER context insertion: {len(tokenizer.encode(user_prompt))}\")",
   "id": "684eb7487a4e49ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Tokens AFTER context insertion: 130\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "**Finally, the code below generates a final prompt using the `prompt_builder` function by combining the system and user prompts. It then sends the prompt to the OpenAI model (`chat_model`) using the `response_generator` function with specified additional options (e.g., `temperature=0`) to generate an AI response. It also calculates the total cost in EUR based on the API usage (`response_full.usage`) for the specific deployment (`gpt-4o-mini`).**"
   ],
   "id": "31565197da769294"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:17.515177Z",
     "start_time": "2025-03-10T18:42:13.210036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_0)\n",
    "additional_options = {\"temperature\": 0.4,}\n",
    "response, response_full = response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options=additional_options)\n",
    "cost_eur = calculate_total_cost(response_usage= response_full.usage,\n",
    "                                deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur} eur')"
   ],
   "id": "61a47f0eda0f0944",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00414349086 eur\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:17.533475Z",
     "start_time": "2025-03-10T18:42:17.530731Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "id": "834e12f3fc4d6430",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   The most popular fashion trend about pants in 2023 is the resurgence and evolution of cargo pants. These are being reimagined with tailored silhouettes, interesting pocket placements, and elevated fabrics, moving beyond traditional khaki and olive colors. Additionally, baggy and wide-leg denim styles are also trending, with a focus on looser fits and floor-grazing lengths.\n",
      "\n",
      "2. Key Points:\n",
      "   â€¢ Cargo pants are making a comeback with tailored designs and elevated fabrics.\n",
      "   â€¢ Baggy and wide-leg denim styles are popular, emphasizing looser fits.\n",
      "   â€¢ The trend includes diverse pant styles such as pedal pushers, wide-leg, and puddle hemlines.\n",
      "\n",
      "3. Sources:\n",
      "   â€¢ www.refinery29.com\n",
      "   â€¢ www.whowhatwear.com\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:17.556461Z",
     "start_time": "2025-03-10T18:42:17.553409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Total Tokens: ', response_full.usage.total_tokens)\n",
    "print('Total Completion Tokens: ', response_full.usage.completion_tokens)\n",
    "print('Total Prompt Tokens: ', response_full.usage.prompt_tokens)"
   ],
   "id": "83efedf17ce7c862",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:  1087\n",
      "Total Completion Tokens:  161\n",
      "Total Prompt Tokens:  926\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Demonstrating Performance",
   "id": "7514793b17a761c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below, two questions (queries) are ... ...",
   "id": "8b67869c3259ae1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1\n",
    "**Question**: According to Vogue, what is a new trend presented by Prada on New York Fashion Week?"
   ],
   "id": "6de426f99dc8bcfe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:17.580079Z",
     "start_time": "2025-03-10T18:42:17.577724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_1 = \"According to Vogue, what is a new trend presented by Prada on New York Fashion Week?\"\n",
    "max_token_count = 1000"
   ],
   "id": "ca6add389d1d2bed",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:25.192793Z",
     "start_time": "2025-03-10T18:42:17.609623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_emb = get_embedding(text=query_1, client = openai_client, model=emb_name)\n",
    "df_sorted = search_text(df=df, embs_query=query_emb, cosine='distance')\n",
    "\n",
    "current_token_count = len(tokenizer.encode(user_prompt)) + len(tokenizer.encode(system_prompt))\n",
    "# Create context from sorted dataframe according to the max token limit\n",
    "context = control_chunk_context(chunks_sorted_df=df_sorted,\n",
    "                                current_token_count=current_token_count,\n",
    "                                max_token_count=max_token_count,\n",
    "                                tokenizer = tokenizer)\n",
    "context_inprompt = \"\\n----\\n\".join(context)\n",
    "user_prompt_1 = user_prompt.format(query_1, context_inprompt)\n",
    "\n",
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_1)\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_1_1, response_full_1_1 = \\\n",
    "    response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options= additional_options)\n",
    "\n",
    "cost_eur_1_1 = \\\n",
    "    calculate_total_cost(response_usage= response_full.usage, deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_1_1} eur')\n"
   ],
   "id": "e16c21bcf8e08b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00414349086 eur\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:25.204435Z",
     "start_time": "2025-03-10T18:42:25.201100Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_1_1)",
   "id": "788ec7d99d399e93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   Prada presented a trend of \"Perfectly Imperfect\" fashion at New York Fashion Week, characterized by a sense of \"unfinishedness\" with features like irregularly dyed prints and slits that appear torn.\n",
      "\n",
      "2. Key Points:\n",
      "   â€¢ Prada's trend is called \"Perfectly Imperfect.\"\n",
      "   â€¢ It features an \"unfinished\" look with irregularly dyed prints.\n",
      "   â€¢ The design includes slits that appear as if the garment is torn.\n",
      "\n",
      "3. Sources:\n",
      "   â€¢ www.vogue.com\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:27.970508Z",
     "start_time": "2025-03-10T18:42:25.229263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= query_1) #or use: user_prompt_without_context.format(query_1)\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_1_2, response_full_1_2 = response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options=additional_options)\n",
    "cost_eur_1_2 = calculate_total_cost(response_usage= response_full.usage,\n",
    "                                deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_1_2} eur')"
   ],
   "id": "ceaaf7e040805a15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00414349086 eur\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:27.991178Z",
     "start_time": "2025-03-10T18:42:27.988284Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_1_2)",
   "id": "bb251c59934d3f64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prada presented a new trend at New York Fashion Week that focused on minimalist and utilitarian designs. This trend emphasized clean lines, functional details, and a neutral color palette, showcasing a shift towards simplicity and practicality in fashion.\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2\n",
    "**Question**:"
   ],
   "id": "2e50a8bd0da9e2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:43:26.458805Z",
     "start_time": "2025-03-10T18:43:26.456214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_2 = \"According to glamour magazine and whowhatwear.com what are the denim fashion trends for the year 2023?\"\n",
    "max_token_count = 1000"
   ],
   "id": "aa58c3192fbcaed3",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:43:34.030712Z",
     "start_time": "2025-03-10T18:43:27.103424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_emb = get_embedding(text=query_2, client = openai_client, model=emb_name)\n",
    "df_sorted = search_text(df=df, embs_query=query_emb, cosine='distance')\n",
    "\n",
    "current_token_count = len(tokenizer.encode(user_prompt)) + len(tokenizer.encode(system_prompt))\n",
    "# Create context from sorted dataframe according to the max token limit\n",
    "context = control_chunk_context(chunks_sorted_df=df_sorted,\n",
    "                                current_token_count=current_token_count,\n",
    "                                max_token_count=max_token_count,\n",
    "                                tokenizer = tokenizer)\n",
    "context_inprompt = \"\\n----\\n\".join(context)\n",
    "user_prompt_2 = user_prompt.format(query_2, context_inprompt)\n",
    "\n",
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_2)\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_2_1, response_full_2_1 = \\\n",
    "    response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options= additional_options)\n",
    "\n",
    "cost_eur_2_1 = \\\n",
    "    calculate_total_cost(response_usage= response_full.usage, deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_2_1} eur')"
   ],
   "id": "4e49d54c04f16346",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00414349086 eur\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:43:34.042149Z",
     "start_time": "2025-03-10T18:43:34.039121Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_2_1)",
   "id": "ed6c6784e187478",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   The denim fashion trends for 2023, according to Glamour Magazine and WhoWhatWear.com, include baggy and looser-fit denim styles, the return of the denim-on-denim look, and the influence of '90s and '00s fashion with items like denim maxi skirts. There is a focus on relaxed silhouettes, with wide-leg and slouchy fits being prominent.\n",
      "\n",
      "2. Key Points:\n",
      "   â€¢ Baggy and looser-fit denim styles are trending.\n",
      "   â€¢ Denim-on-denim, also known as the Canadian tuxedo, is making a comeback.\n",
      "   â€¢ '90s and '00s fashion influences, such as denim maxi skirts, are popular.\n",
      "   â€¢ Relaxed silhouettes are favored over skinny jeans.\n",
      "\n",
      "3. Sources:\n",
      "   â€¢ www.glamour.com\n",
      "   â€¢ www.whowhatwear.com\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:43:40.377452Z",
     "start_time": "2025-03-10T18:43:34.123191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= query_2) #or use: user_prompt_without_context.format(query_2)\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_2_2, response_full_2_2 = response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options=additional_options)\n",
    "\n",
    "cost_eur_2_2 = calculate_total_cost(response_usage= response_full.usage,deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_2_2} eur')"
   ],
   "id": "9139d4de112837db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.00414349086 eur\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:43:40.455898Z",
     "start_time": "2025-03-10T18:43:40.452945Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_2_2)",
   "id": "6102b25283d411a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2023, denim fashion trends, as highlighted by Glamour Magazine and Who What Wear, focus on a mix of nostalgic and modern styles. Key trends include:\n",
      "\n",
      "1. **Baggy and Relaxed Fits**: Loose-fitting jeans, reminiscent of the 90s and early 2000s, are making a strong comeback. These styles prioritize comfort and a laid-back aesthetic.\n",
      "\n",
      "2. **Low-Rise Jeans**: The low-rise trend is resurging, appealing to those who favor a more daring and retro look.\n",
      "\n",
      "3. **Cargo and Utility Styles**: Denim with cargo pockets and utility-inspired details are popular, blending functionality with fashion.\n",
      "\n",
      "4. **Denim Maxi Skirts**: Long denim skirts are trending, offering a versatile and chic alternative to jeans.\n",
      "\n",
      "5. **Patchwork and Distressed Denim**: These styles add a unique, personalized touch to denim pieces, with patchwork designs and distressed details being particularly popular.\n",
      "\n",
      "6. **Colored and Printed Denim**: Beyond traditional blue, colored and printed denim options are gaining traction, allowing for more expressive and bold fashion choices.\n",
      "\n",
      "7. **Double Denim**: The \"Canadian tuxedo\" look, or wearing denim on denim, is being embraced with modern twists, such as mixing different washes or textures.\n",
      "\n",
      "These trends reflect a blend of nostalgia and innovation, catering to a wide range of personal styles and preferences.\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:42:40.452052Z",
     "start_time": "2025-03-10T18:42:40.450062Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f710af2445d92eec",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
