{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom Chatbot Notebook",
   "id": "a71c5706072dcb2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "An OpenAI client is initialised by using environment variables and a tokenizer is set up for a specific model (`gpt-4o-mini-2024-07-18`). Also,the necessary libraries and custom utility functions are imported.",
   "id": "876d4a4fd073a812"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:09.325902Z",
     "start_time": "2025-03-10T18:34:09.309694Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "# Custom Functions\n",
    "from fncs.utilities import (\n",
    "    create_openai_client,\n",
    "    response_generator,\n",
    "    prompt_builder,\n",
    "    calculate_total_cost\n",
    "    )\n",
    "from fncs.retrieval import (\n",
    "    get_embedding,\n",
    "    search_text,\n",
    "    control_chunk_context\n",
    "    )\n",
    "\n",
    "# Load environment vars:\n",
    "load_dotenv()\n",
    "base_url_voc = os.getenv(\"OPENAI_BASE_VOC\")\n",
    "api_key_voc = os.getenv(\"OPENAI_API_VOC\")\n",
    "# Deployment model names\n",
    "chat_name = 'gpt-4o-mini' # 'gpt-4o-mini-2024-07-18' # 'gpt-4o-mini'\n",
    "emb_name = 'text-embedding-3-large'\n",
    "# Initialising OpenAI client\n",
    "openai_client = create_openai_client(api_key= api_key_voc, base_url= base_url_voc)\n",
    "tokenizer = tiktoken.encoding_for_model(chat_name)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading dataset",
   "id": "aa1832c099f587ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:09.401778Z",
     "start_time": "2025-03-10T18:34:09.337912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "proj_dir = Path(os.getcwd())\n",
    "df = pd.read_csv(proj_dir / \"data\" / \"2023_fashion_trends_embeddings.csv\")\n",
    "df.head(3)"
   ],
   "id": "9233858f77e0c6bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "1  Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "2  Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.06084602698683739, -0.00787690281867981, -...  \n",
       "1  [-0.06700262427330017, -0.014003804884850979, ...  \n",
       "2  [-0.05102064833045006, -0.00858586560934782, -...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.06084602698683739, -0.00787690281867981, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.06700262427330017, -0.014003804884850979, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.05102064833045006, -0.00858586560934782, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The embeddings are stored as text/string in the DataFrame and need to be converted to lists/arrays",
   "id": "dfb834f8176e49a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:10.569848Z",
     "start_time": "2025-03-10T18:34:09.445091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "# Converting the string representations of embeddings to actual lists\n",
    "df['embeddings'] = df['embeddings'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
   ],
   "id": "72f7af3db628d262",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Checking transformation",
   "id": "ea2d89ae8d023bd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:10.617006Z",
     "start_time": "2025-03-10T18:34:10.612508Z"
    }
   },
   "cell_type": "code",
   "source": "type(df[['embeddings']].iloc[0].values[0])",
   "id": "7d4c69ab4591f282",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculating Cosine Distances based on query\n",
   "id": "16b223bc1c9826e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below I create a query string about fashion trends in 2023. Then, by using the `get_embedding` function, the embeddings of the query are generated, by passing the query, OpenAI client, and embedding model as inputs.",
   "id": "93ba9094776a441b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.504156Z",
     "start_time": "2025-03-10T18:34:10.625765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is the most popular fashion trend about pants in 2023?\"\n",
    "query_emb = get_embedding(text=query, client = openai_client, model=emb_name)"
   ],
   "id": "54410f634493630e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The DataFrame `df` is sorted based on the cosine distance between the query embedding (`query_emb`) and the embeddings in the DataFrame using the `search_text` function, and stores the result in `df_sorted`.",
   "id": "586755641dd11503"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.565136Z",
     "start_time": "2025-03-10T18:34:12.509290Z"
    }
   },
   "cell_type": "code",
   "source": "df_sorted = search_text(df=df, embs_query=query_emb, cosine='distance')",
   "id": "651fdb4f27f1ee03",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.588418Z",
     "start_time": "2025-03-10T18:34:12.578836Z"
    }
   },
   "cell_type": "code",
   "source": "df_sorted.head()",
   "id": "9c4e84a9dd56756e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 text  \\\n",
       "1   Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "3   Title: 7 Fashion Trends That Will Take Over 20...   \n",
       "58  Title: Spring/Summer 2023 Fashion Trends: 21 E...   \n",
       "44  Title: Spring/Summer 2023 Fashion Trends: 21 E...   \n",
       "19  Title: 9 Spring 2023 Fashion Trends You’ll Wan...   \n",
       "\n",
       "                                           embeddings  distance  \n",
       "1   [-0.06700262427330017, -0.014003804884850979, ...  0.273721  \n",
       "3   [-0.05067730322480202, -0.02512504905462265, -...  0.307084  \n",
       "58  [-0.03485928103327751, -0.015784457325935364, ...  0.309776  \n",
       "44  [-0.04672637954354286, -0.03269721940159798, -...  0.310095  \n",
       "19  [-0.04425228014588356, -0.035396404564380646, ...  0.355568  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.06700262427330017, -0.014003804884850979, ...</td>\n",
       "      <td>0.273721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: 7 Fashion Trends That Will Take Over 20...</td>\n",
       "      <td>[-0.05067730322480202, -0.02512504905462265, -...</td>\n",
       "      <td>0.307084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Title: Spring/Summer 2023 Fashion Trends: 21 E...</td>\n",
       "      <td>[-0.03485928103327751, -0.015784457325935364, ...</td>\n",
       "      <td>0.309776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Title: Spring/Summer 2023 Fashion Trends: 21 E...</td>\n",
       "      <td>[-0.04672637954354286, -0.03269721940159798, -...</td>\n",
       "      <td>0.310095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Title: 9 Spring 2023 Fashion Trends You’ll Wan...</td>\n",
       "      <td>[-0.04425228014588356, -0.035396404564380646, ...</td>\n",
       "      <td>0.355568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt Template\n",
    "\n"
   ],
   "id": "97638c85ae6d747d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating the system prompt to be used in the chatbot",
   "id": "da394a06d778b32a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.695406Z",
     "start_time": "2025-03-10T18:34:12.691548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are an expert fashion trend analyser. Based only on the provided information you must analyse and summarise the trends and provide an accurate answer.\"\n",
    "\n",
    "print(f\"System Prompt Tokens: {len(tokenizer.encode(system_prompt))}\")"
   ],
   "id": "16608bc3cc579ba2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt Tokens: 28\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating the user prompt to be used in the chatbot",
   "id": "fc2cdc335fb53bc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.753780Z",
     "start_time": "2025-03-10T18:34:12.750133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_prompt = \\\n",
    "\"\"\"\n",
    "***Question: {}\n",
    "\n",
    "***Context:\n",
    "<--Start of Context-->\n",
    "{}\n",
    "<--End of Context-->\n",
    "\n",
    "**Instructions:\n",
    "- Answer based ONLY on the provided context above\n",
    "- Do not include external knowledge\n",
    "- Be concise and specific\n",
    "\n",
    "**Required Format:\n",
    "1. Answer:\n",
    "   [Your detailed response here]\n",
    "\n",
    "2. Key Points:\n",
    "   • [Bullet point 1]\n",
    "   • [Bullet point 2]\n",
    "   • [...]\n",
    "\n",
    "3. Sources:\n",
    "   • [Source URL 1]\n",
    "   • [Source URL 2]\n",
    "\n",
    "Note: If the answer cannot be determined from the provided context,\n",
    "state: \"Cannot be determined from the given context.\"\n",
    "\"\"\"\n",
    "print(f\"User Prompt Tokens BEFORE context insertion: {len(tokenizer.encode(user_prompt))}\")"
   ],
   "id": "732e48236e9a6d72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Tokens BEFORE context insertion: 130\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.808574Z",
     "start_time": "2025-03-10T18:34:12.805160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# to be used in performance demonstration later\n",
    "user_prompt_without_context = \\\n",
    "\"\"\"\n",
    "***Question: {}\n",
    "\n",
    "**Instructions:\n",
    "- Be concise and specific\n",
    "\n",
    "**Required Format:\n",
    "1. Answer:\n",
    "   [Your detailed response here]\n",
    "\n",
    "2. Key Points:\n",
    "   • [Bullet point 1]\n",
    "   • [Bullet point 2]\n",
    "   • [...]\n",
    "\n",
    "3. Sources:\n",
    "   • [Source URL 1]\n",
    "   • [Source URL 2]\n",
    "\"\"\"\n",
    "print(f\"User Prompt Tokens BEFORE context insertion: {len(tokenizer.encode(user_prompt))}\")"
   ],
   "id": "f730b283e8594761",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Tokens BEFORE context insertion: 130\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Apply token controller function ( fnc: control_chunk_context )",
   "id": "3649988fc071c9bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The variable `max_token_count` to 1000, serves as a limit for the total number of tokens allowed in a prompt.",
   "id": "839f6afd7c2c2e41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.871099Z",
     "start_time": "2025-03-10T18:34:12.868251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#parameter that control the prompt tokens:\n",
    "max_token_count = 1000"
   ],
   "id": "22322f84eb10bf97",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The code below calculates the current token count of the prompts (system and user) and generates a context by selecting data from the sorted DataFrame (`df_sorted`) based on a maximum allowed token limit (`max_token_count`) using the `control_chunk_context` function.",
   "id": "3c777d5527194df7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.909371Z",
     "start_time": "2025-03-10T18:34:12.904906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_token_count = len(tokenizer.encode(user_prompt)) + len(tokenizer.encode(system_prompt))\n",
    "# Create context from sorted dataframe according to the max token limit\n",
    "context = control_chunk_context(\n",
    "    df_sorted,\n",
    "    current_token_count,\n",
    "    max_token_count,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ],
   "id": "ff7b5de9fb7ce93e",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Below, the final `user_prompt` is created by inserting the generated `context` into the prompt template and by formatting it with the query and context.",
   "id": "792d744256c0ffba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.919077Z",
     "start_time": "2025-03-10T18:34:12.915884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prompt template params\n",
    "context_inprompt = \"\\n----\\n\".join(context)\n",
    "user_prompt_0 = user_prompt.format(query, context_inprompt)\n",
    "\n",
    "print(user_prompt)"
   ],
   "id": "8987fcd4455e42bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Question: {}\n",
      "\n",
      "***Context:\n",
      "<--Start of Context-->\n",
      "{}\n",
      "<--End of Context-->\n",
      "\n",
      "**Instructions:\n",
      "- Answer based ONLY on the provided context above\n",
      "- Do not include external knowledge\n",
      "- Be concise and specific\n",
      "\n",
      "**Required Format:\n",
      "1. Answer:\n",
      "   [Your detailed response here]\n",
      "\n",
      "2. Key Points:\n",
      "   • [Bullet point 1]\n",
      "   • [Bullet point 2]\n",
      "   • [...]\n",
      "\n",
      "3. Sources:\n",
      "   • [Source URL 1]\n",
      "   • [Source URL 2]\n",
      "\n",
      "Note: If the answer cannot be determined from the provided context,\n",
      "state: \"Cannot be determined from the given context.\"\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:12.940028Z",
     "start_time": "2025-03-10T18:34:12.937112Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"User Prompt Tokens AFTER context insertion: {len(tokenizer.encode(user_prompt))}\")",
   "id": "684eb7487a4e49ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Tokens AFTER context insertion: 130\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "**Finally, the code below generates a final prompt using the `prompt_builder` function by combining the system and user prompts. It then sends the prompt to the OpenAI model (`chat_model`) using the `response_generator` function with specified additional options (e.g., `temperature=0`) to generate an AI response. It also calculates the total cost in EUR based on the API usage (`response_full.usage`) for the specific deployment (`gpt-4o-mini`).**"
   ],
   "id": "31565197da769294"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:16.350684Z",
     "start_time": "2025-03-10T18:34:12.969429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_0)\n",
    "additional_options = {\"temperature\": 0.4,}\n",
    "response, response_full = response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options=additional_options)\n",
    "cost_eur = calculate_total_cost(response_usage= response_full.usage,\n",
    "                                deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur} eur')"
   ],
   "id": "61a47f0eda0f0944",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.0002631777 eur\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:16.372135Z",
     "start_time": "2025-03-10T18:34:16.368823Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "id": "834e12f3fc4d6430",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   The most popular fashion trend about pants in 2023 is the resurgence of cargo pants, which are being reimagined with tailored silhouettes, unique pocket placements, and luxurious fabrics. Additionally, baggy denim styles are also trending, with a focus on looser fits and timeless cuts. Overall, trousers are a significant focus for the season, with a variety of styles including wide-leg, puddle hemlines, and slouchy fits gaining popularity.\n",
      "\n",
      "2. Key Points:\n",
      "   • Cargo pants are making a comeback with tailored designs and elevated materials.\n",
      "   • Baggy denim remains popular, featuring looser fits and versatile styling options.\n",
      "   • The trend encompasses a variety of trouser styles, including wide-leg and puddle hemlines.\n",
      "\n",
      "3. Sources:\n",
      "   • www.refinery29.com\n",
      "   • www.whowhatwear.com\n",
      "   • www.glamour.com\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:16.500867Z",
     "start_time": "2025-03-10T18:34:16.496820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Total Tokens: ', response_full.usage.total_tokens)\n",
    "print('Total Completion Tokens: ', response_full.usage.completion_tokens)\n",
    "print('Total Prompt Tokens: ', response_full.usage.prompt_tokens)"
   ],
   "id": "83efedf17ce7c862",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:  1110\n",
      "Total Completion Tokens:  184\n",
      "Total Prompt Tokens:  926\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Demonstrating Performance",
   "id": "7514793b17a761c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below, two questions (queries) are ... ...",
   "id": "8b67869c3259ae1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1\n",
    "**Question**: According to Vogue, what is a new trend presented by Prada on New York Fashion Week?"
   ],
   "id": "6de426f99dc8bcfe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:16.529423Z",
     "start_time": "2025-03-10T18:34:16.526827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_1 = \"According to Vogue, what is a new trend presented by Prada on New York Fashion Week?\"\n",
    "max_token_count = 1000"
   ],
   "id": "ca6add389d1d2bed",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:19.906817Z",
     "start_time": "2025-03-10T18:34:16.559622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_emb = get_embedding(text=query_1, client = openai_client, model=emb_name)\n",
    "df_sorted = search_text(df=df, embs_query=query_emb, cosine='distance')\n",
    "\n",
    "current_token_count = len(tokenizer.encode(user_prompt)) + len(tokenizer.encode(system_prompt))\n",
    "# Create context from sorted dataframe according to the max token limit\n",
    "context = control_chunk_context(chunks_sorted_df=df_sorted,\n",
    "                                current_token_count=current_token_count,\n",
    "                                max_token_count=max_token_count,\n",
    "                                tokenizer = tokenizer)\n",
    "context_inprompt = \"\\n----\\n\".join(context)\n",
    "user_prompt_1 = user_prompt.format(query_1, context_inprompt)\n",
    "\n",
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_1)\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_1_1, response_full_1_1 = \\\n",
    "    response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options= additional_options)\n",
    "\n",
    "cost_eur_1_1 = \\\n",
    "    calculate_total_cost(response_usage= response_full.usage, deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_1_1} eur')\n"
   ],
   "id": "e16c21bcf8e08b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.0002631777 eur\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:19.929689Z",
     "start_time": "2025-03-10T18:34:19.927073Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_1_1)",
   "id": "788ec7d99d399e93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   A new trend presented by Prada at New York Fashion Week is the \"Perfectly Imperfect\" style, characterized by a satin midi skirt that features an irregularly dyed print and a slit designed to give the appearance of being torn. This trend evokes a sense of \"unfinishedness\" in fashion.\n",
      "\n",
      "2. Key Points:\n",
      "   • Prada's satin midi skirt showcases an \"unfinished\" aesthetic.\n",
      "   • The design includes an irregularly dyed print and a slit that mimics a torn look.\n",
      "\n",
      "3. Sources:\n",
      "   • www.vogue.com\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:22.591770Z",
     "start_time": "2025-03-10T18:34:19.949912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= query_1) #or use: user_prompt_without_context.format(query_1)\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_1_2, response_full_1_2 = response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options=additional_options)\n",
    "cost_eur_1_2 = calculate_total_cost(response_usage= response_full.usage,\n",
    "                                deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_1_2} eur')"
   ],
   "id": "ceaaf7e040805a15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.0002631777 eur\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:22.611744Z",
     "start_time": "2025-03-10T18:34:22.608750Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_1_2)",
   "id": "bb251c59934d3f64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of October 2023, Prada showcased a notable trend at New York Fashion Week that emphasizes a blend of sophistication and practicality. The collection featured a mix of tailored silhouettes with unexpected elements, such as bold colors and unique textures. This trend reflects a growing preference for versatile pieces that can transition from day to night, highlighting the importance of functionality in high fashion. Additionally, Prada's use of innovative materials and sustainable practices aligns with the broader industry movement towards eco-conscious fashion. Overall, the trend signifies a shift towards modern elegance that prioritizes both style and wearability.\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2\n",
    "**Question**:"
   ],
   "id": "2e50a8bd0da9e2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:22.630624Z",
     "start_time": "2025-03-10T18:34:22.628144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_2 = \"What an indie sleaze is and how it affected the fashion trends of 2023?\"\n",
    "max_token_count = 1000"
   ],
   "id": "aa58c3192fbcaed3",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:29.144613Z",
     "start_time": "2025-03-10T18:34:22.646819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_emb = get_embedding(text=query_2, client = openai_client, model=emb_name)\n",
    "df_sorted = search_text(df=df, embs_query=query_emb, cosine='distance')\n",
    "\n",
    "current_token_count = len(tokenizer.encode(user_prompt)) + len(tokenizer.encode(system_prompt))\n",
    "# Create context from sorted dataframe according to the max token limit\n",
    "context = control_chunk_context(chunks_sorted_df=df_sorted,\n",
    "                                current_token_count=current_token_count,\n",
    "                                max_token_count=max_token_count,\n",
    "                                tokenizer = tokenizer)\n",
    "context_inprompt = \"\\n----\\n\".join(context)\n",
    "user_prompt_2 = user_prompt.format(query_2, context_inprompt)\n",
    "\n",
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= user_prompt_2)\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_2_1, response_full_2_1 = \\\n",
    "    response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options= additional_options)\n",
    "\n",
    "cost_eur_2_1 = \\\n",
    "    calculate_total_cost(response_usage= response_full.usage, deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_2_1} eur')"
   ],
   "id": "4e49d54c04f16346",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.0002631777 eur\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:29.164804Z",
     "start_time": "2025-03-10T18:34:29.161832Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_2_1)",
   "id": "ed6c6784e187478",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Answer:\n",
      "   Indie sleaze is a fashion aesthetic that draws inspiration from the edgy, carefree styles of the late 2000s and early 2010s, characterized by elements such as distressed denim, layered tops, and utilitarian details. In 2023, this trend has significantly influenced fashion, as seen in the spring/summer collections that feature muddy hues, oversized pockets, and cargo shapes. The resurgence of this nostalgic style aligns with other trends like sheer clothing, daytime shine, and reimagined denim, indicating a broader embrace of retro influences across various fashion categories.\n",
      "\n",
      "2. Key Points:\n",
      "   • Indie sleaze reflects a nostalgic return to edgy styles from the late 2000s and early 2010s.\n",
      "   • Key elements include distressed denim, layered tops, and modern utility detailing.\n",
      "   • The trend is part of a larger movement in 2023 that includes sheer clothing, daytime shine, and innovative denim styles.\n",
      "\n",
      "3. Sources:\n",
      "   • www.whowhatwear.com\n",
      "   • www.refinery29.com\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:34.470836Z",
     "start_time": "2025-03-10T18:34:29.183412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_prompt = prompt_builder(system_content= system_prompt, user_content_prompt= query_2) #or use: user_prompt_without_context.format(query_2)\n",
    "additional_options = {\"temperature\": 0,}\n",
    "\n",
    "response_2_2, response_full_2_2 = response_generator(openai_client, chat_model=chat_name, prompts=final_prompt, options=additional_options)\n",
    "\n",
    "cost_eur_2_2 = calculate_total_cost(response_usage= response_full.usage,deployment_name= chat_name)\n",
    "print(f'Query Completion Total Cost is: {cost_eur_2_2} eur')"
   ],
   "id": "9139d4de112837db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Completion Total Cost is: 0.0002631777 eur\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:34.489495Z",
     "start_time": "2025-03-10T18:34:34.486578Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_2_2)",
   "id": "6102b25283d411a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indie sleaze is a fashion and cultural aesthetic that emerged in the early 2000s, characterized by a mix of grunge, punk, and vintage influences. It often features elements such as oversized clothing, thrifted pieces, graphic tees, skinny jeans, and a general DIY ethos. The look is often accessorized with items like beanies, chunky jewelry, and retro sunglasses, reflecting a carefree, rebellious attitude.\n",
      "\n",
      "In 2023, indie sleaze made a notable comeback, influencing fashion trends significantly. This resurgence can be attributed to a nostalgia for early 2000s culture, driven by social media platforms like TikTok and Instagram, where vintage and retro styles are celebrated. Key trends that emerged from this revival include:\n",
      "\n",
      "1. **Thrift Culture**: A renewed interest in second-hand shopping and sustainable fashion, with many consumers seeking unique, vintage pieces that embody the indie sleaze aesthetic.\n",
      "\n",
      "2. **Layering and Oversized Silhouettes**: The trend embraced oversized jackets, baggy jeans, and layered outfits, allowing for a relaxed and comfortable style that resonates with the indie sleaze vibe.\n",
      "\n",
      "3. **Graphic Tees and Band Merchandise**: A resurgence of graphic tees featuring nostalgic band logos or quirky designs became popular, reflecting the DIY spirit of the indie sleaze movement.\n",
      "\n",
      "4. **Bold Accessories**: Chunky jewelry, statement belts, and retro sunglasses became essential elements of outfits, adding a playful and eclectic touch.\n",
      "\n",
      "5. **Mixing High and Low Fashion**: The trend encouraged a blend of high-end pieces with thrifted finds, promoting an individualistic approach to style.\n",
      "\n",
      "Overall, the indie sleaze revival in 2023 highlighted a desire for authenticity and self-expression in fashion, appealing to a generation that values both nostalgia and sustainability.\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:34:34.510606Z",
     "start_time": "2025-03-10T18:34:34.508684Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f710af2445d92eec",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
